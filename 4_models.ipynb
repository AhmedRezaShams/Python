{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedRezaShams/Python/blob/main/4_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du8rS-BBLzRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f648a8-de47-4001-a9c2-ab6b70c29815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: bnlp in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn nltk bnlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bnlp_toolkit"
      ],
      "metadata": {
        "id": "mY2XPNcDMdl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17db0d50-d54b-4368-b40c-98eab2399088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.1.99)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.11.3)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.66.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (6.1.1)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (2.31.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.8)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2023.7.22)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U bnlp_toolkit"
      ],
      "metadata": {
        "id": "DeHDyUY7Mr2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a215dfa-845d-4cfe-af48-99870cc97875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.1.99)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.11.3)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.66.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (6.1.1)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (2.31.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.8)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2023.7.22)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from bnlp import NLTKTokenizer"
      ],
      "metadata": {
        "id": "PvRAgCi-Myrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the file path of the XLSX file\n",
        "file_path = \"/content/Data Mining.xlsx\"\n",
        "\n",
        "# Read the XLSX file into a pandas DataFrame\n",
        "try:\n",
        "    data = pd.read_excel(file_path)\n",
        "except UnicodeDecodeError:\n",
        "    print(\"Error: Failed to decode XLSX file. Please check the encoding.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{file_path}' not found.\")\n",
        "\n",
        "# Now you can work with the 'data' DataFrame containing the contents of the XLSX file.\n"
      ],
      "metadata": {
        "id": "yJ8rj2MpM71m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_column = 'class'\n",
        "unique_classes = data[class_column].unique()\n",
        "num_classes = len(unique_classes)\n",
        "\n",
        "print(f\"Number of unique classes: {num_classes}\")\n",
        "print(\"Unique classes:\", unique_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLblVTXZM75A",
        "outputId": "0947b322-6094-4e29-9dfa-f12f5c7b2a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique classes: 2\n",
            "Unique classes: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_column = 'class'\n",
        "\n",
        "# Count the occurrences of each class\n",
        "class_counts = data[class_column].value_counts()\n",
        "\n",
        "print(\"Class distribution:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIf-IGq_WKwr",
        "outputId": "1f92839c-2600-4d7f-b943-58a8102c000a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution:\n",
            "0    267\n",
            "1    267\n",
            "Name: class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "D9sBsaVEYp2H",
        "outputId": "9a361884-8bde-4ce4-b918-ebb1af65bca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               content  class  Unnamed: 2\n",
              "0    In  this  paper,  the  design  of  3D  Kanji  ...      0  Original=0\n",
              "1    This paper introduces the concept of designing...      1        AI=1\n",
              "2    3D Kanji is a 3D form of a Kanji character, wh...      0         NaN\n",
              "3    A  multimedia  dictionary  using  3D  Kanji  f...      1         NaN\n",
              "4    The impression of 3D Kanji can be changed by t...      0         NaN\n",
              "..                                                 ...    ...         ...\n",
              "529  I would like to express my gratitude for the i...      1         NaN\n",
              "530  And  the  total  number  of  pixels  of  part ...      0         NaN\n",
              "531  The images taken on July 22 and August 8 exhib...      1         NaN\n",
              "532  Model  formula  which  finds  predictions  of ...      0         NaN\n",
              "533  A model formula, designed to predict plant hei...      1         NaN\n",
              "\n",
              "[534 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22533787-48e9-480d-9ce8-ae163f200edb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>class</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In  this  paper,  the  design  of  3D  Kanji  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Original=0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This paper introduces the concept of designing...</td>\n",
              "      <td>1</td>\n",
              "      <td>AI=1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3D Kanji is a 3D form of a Kanji character, wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A  multimedia  dictionary  using  3D  Kanji  f...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The impression of 3D Kanji can be changed by t...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>I would like to express my gratitude for the i...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>And  the  total  number  of  pixels  of  part ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>The images taken on July 22 and August 8 exhib...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>Model  formula  which  finds  predictions  of ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>A model formula, designed to predict plant hei...</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>534 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22533787-48e9-480d-9ce8-ae163f200edb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-22533787-48e9-480d-9ce8-ae163f200edb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-22533787-48e9-480d-9ce8-ae163f200edb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd2143f0-a952-411e-ad32-e3012a7ad504\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd2143f0-a952-411e-ad32-e3012a7ad504')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd2143f0-a952-411e-ad32-e3012a7ad504 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow keras scikit-learn"
      ],
      "metadata": {
        "id": "aV8Gff10ZXSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6315a480-371c-4d2e-d193-426f6199b659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = data['content']\n",
        "y = data['class']\n",
        "\n",
        "# Encode the target labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad sequences to make them of the same length\n",
        "max_sequence_length = 500  # You can adjust this value based on your dataset and text length\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
        "\n",
        "# Convert the target labels to one-hot encoding for 2 classes\n",
        "y_train_onehot = to_categorical(y_train, num_classes=2)\n",
        "y_test_onehot = to_categorical(y_test, num_classes=2)\n"
      ],
      "metadata": {
        "id": "eeqvejQWZbyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=2, activation='relu'))  # For 3-class classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7TmsMDZ8Z56C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_padded, y_train_onehot, batch_size=32, epochs=100, validation_data=(X_test_padded, y_test_onehot))\n",
        "\n",
        "# Evaluate the model\n",
        "_, accuracy = model.evaluate(X_test_padded, y_test_onehot)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQt-NxZBZ_ZT",
        "outputId": "8231298e-4d7d-4434-f0d6-1f78b25058c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 17s 946ms/step - loss: 1.7840 - accuracy: 0.4965 - val_loss: 0.7300 - val_accuracy: 0.4299\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 14s 941ms/step - loss: 0.8983 - accuracy: 0.5293 - val_loss: 1.0752 - val_accuracy: 0.4112\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 14s 992ms/step - loss: 1.0131 - accuracy: 0.6019 - val_loss: 1.0349 - val_accuracy: 0.3925\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.9143 - accuracy: 0.6019 - val_loss: 0.9203 - val_accuracy: 0.4019\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.7861 - accuracy: 0.5761 - val_loss: 0.7879 - val_accuracy: 0.4299\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 14s 1000ms/step - loss: 0.6891 - accuracy: 0.5293 - val_loss: 0.7500 - val_accuracy: 0.4299\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.6580 - accuracy: 0.5902 - val_loss: 0.7484 - val_accuracy: 0.3925\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.6506 - accuracy: 0.6440 - val_loss: 0.7447 - val_accuracy: 0.3458\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.6317 - accuracy: 0.6768 - val_loss: 0.7522 - val_accuracy: 0.3364\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.6158 - accuracy: 0.7260 - val_loss: 0.7638 - val_accuracy: 0.3178\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.5969 - accuracy: 0.8009 - val_loss: 0.7792 - val_accuracy: 0.3084\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.5712 - accuracy: 0.8056 - val_loss: 0.8051 - val_accuracy: 0.2991\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.5323 - accuracy: 0.8267 - val_loss: 0.9516 - val_accuracy: 0.2897\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.4495 - accuracy: 0.8618 - val_loss: 1.9700 - val_accuracy: 0.2991\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 13s 948ms/step - loss: 0.2947 - accuracy: 0.9508 - val_loss: 4.9737 - val_accuracy: 0.3364\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 12s 821ms/step - loss: 0.1285 - accuracy: 0.9649 - val_loss: 3.4923 - val_accuracy: 0.4112\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 14s 932ms/step - loss: 0.1435 - accuracy: 0.9859 - val_loss: 3.6173 - val_accuracy: 0.3738\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0506 - accuracy: 0.9883 - val_loss: 5.7028 - val_accuracy: 0.3738\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0464 - accuracy: 0.9953 - val_loss: 6.8979 - val_accuracy: 0.4112\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0289 - accuracy: 0.9977 - val_loss: 6.4702 - val_accuracy: 0.3832\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 6.4582 - val_accuracy: 0.3832\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 6.5778 - val_accuracy: 0.4019\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0240 - accuracy: 0.9977 - val_loss: 6.2316 - val_accuracy: 0.4019\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 6.6730 - val_accuracy: 0.4019\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 6.2878 - val_accuracy: 0.4486\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 6.5884 - val_accuracy: 0.4019\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 6.9572 - val_accuracy: 0.4112\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 13s 977ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 6.9716 - val_accuracy: 0.4019\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 12s 884ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 6.9783 - val_accuracy: 0.4019\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 13s 868ms/step - loss: 0.0051 - accuracy: 0.9953 - val_loss: 6.9537 - val_accuracy: 0.4019\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 14s 935ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 6.9971 - val_accuracy: 0.4112\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 7.0306 - val_accuracy: 0.3925\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 7.0294 - val_accuracy: 0.3925\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0048 - accuracy: 0.9953 - val_loss: 7.0292 - val_accuracy: 0.3925\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 7.0383 - val_accuracy: 0.4019\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0044 - accuracy: 0.9953 - val_loss: 7.0372 - val_accuracy: 0.4019\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0049 - accuracy: 0.9953 - val_loss: 7.0695 - val_accuracy: 0.3925\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 7.0846 - val_accuracy: 0.3832\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 7.1842 - val_accuracy: 0.3832\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 7.0446 - val_accuracy: 0.3832\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 7.1370 - val_accuracy: 0.3832\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 7.2404 - val_accuracy: 0.4019\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 14s 984ms/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 6.9728 - val_accuracy: 0.3925\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 12s 867ms/step - loss: 0.0039 - accuracy: 0.9977 - val_loss: 6.8787 - val_accuracy: 0.4112\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 13s 876ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 7.3442 - val_accuracy: 0.3832\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 14s 959ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 7.2370 - val_accuracy: 0.3925\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0041 - accuracy: 0.9977 - val_loss: 7.1851 - val_accuracy: 0.3925\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 13s 961ms/step - loss: 0.0038 - accuracy: 0.9977 - val_loss: 7.1220 - val_accuracy: 0.4019\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 7.0981 - val_accuracy: 0.3925\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0040 - accuracy: 0.9953 - val_loss: 7.2390 - val_accuracy: 0.3925\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 13s 972ms/step - loss: 0.0043 - accuracy: 0.9977 - val_loss: 7.2046 - val_accuracy: 0.3925\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 14s 995ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 7.2475 - val_accuracy: 0.3925\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 7.4373 - val_accuracy: 0.3832\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 13s 955ms/step - loss: 0.0043 - accuracy: 0.9953 - val_loss: 7.2059 - val_accuracy: 0.3925\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 12s 819ms/step - loss: 0.0042 - accuracy: 0.9977 - val_loss: 7.3078 - val_accuracy: 0.3832\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 7.3911 - val_accuracy: 0.3738\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0045 - accuracy: 0.9953 - val_loss: 7.3840 - val_accuracy: 0.3738\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0041 - accuracy: 0.9953 - val_loss: 7.3574 - val_accuracy: 0.3925\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 14s 985ms/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.4210 - val_accuracy: 0.3925\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.4695 - val_accuracy: 0.3738\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 7.4310 - val_accuracy: 0.3925\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 15s 1s/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 7.4844 - val_accuracy: 0.3925\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 7.4795 - val_accuracy: 0.3925\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 14s 994ms/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 7.4185 - val_accuracy: 0.3925\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 13s 956ms/step - loss: 0.0039 - accuracy: 0.9977 - val_loss: 6.7797 - val_accuracy: 0.4112\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 13s 925ms/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 6.9527 - val_accuracy: 0.4019\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 12s 829ms/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 6.9871 - val_accuracy: 0.4019\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 14s 950ms/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 7.1704 - val_accuracy: 0.4019\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 14s 999ms/step - loss: 0.0037 - accuracy: 0.9953 - val_loss: 7.2161 - val_accuracy: 0.4019\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 17s 1s/step - loss: 0.0036 - accuracy: 0.9953 - val_loss: 7.5111 - val_accuracy: 0.4112\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 14s 938ms/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.4381 - val_accuracy: 0.4019\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0035 - accuracy: 0.9953 - val_loss: 7.4659 - val_accuracy: 0.3832\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0037 - accuracy: 0.9953 - val_loss: 7.5270 - val_accuracy: 0.3925\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 13s 978ms/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.4981 - val_accuracy: 0.3645\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.5311 - val_accuracy: 0.4019\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0035 - accuracy: 0.9953 - val_loss: 7.5318 - val_accuracy: 0.4112\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 7.5572 - val_accuracy: 0.3832\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0032 - accuracy: 0.9977 - val_loss: 7.5339 - val_accuracy: 0.4112\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0036 - accuracy: 0.9953 - val_loss: 7.5287 - val_accuracy: 0.4112\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 12s 898ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.4935 - val_accuracy: 0.4019\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 12s 835ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 7.5004 - val_accuracy: 0.4019\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 14s 921ms/step - loss: 0.0038 - accuracy: 0.9953 - val_loss: 7.5108 - val_accuracy: 0.4019\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 7.6454 - val_accuracy: 0.3925\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 14s 999ms/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 7.5258 - val_accuracy: 0.3925\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 18s 1s/step - loss: 0.0036 - accuracy: 0.9977 - val_loss: 7.5656 - val_accuracy: 0.3925\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 7.5347 - val_accuracy: 0.3925\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 13s 965ms/step - loss: 0.0032 - accuracy: 0.9977 - val_loss: 7.6279 - val_accuracy: 0.4112\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 7.6639 - val_accuracy: 0.4112\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 7.5331 - val_accuracy: 0.3925\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 14s 988ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 7.7392 - val_accuracy: 0.3551\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0043 - accuracy: 0.9977 - val_loss: 7.7514 - val_accuracy: 0.3925\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 14s 988ms/step - loss: 0.0040 - accuracy: 0.9977 - val_loss: 7.5912 - val_accuracy: 0.4112\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 12s 899ms/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 7.5844 - val_accuracy: 0.4112\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 12s 813ms/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 7.5753 - val_accuracy: 0.4019\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 14s 935ms/step - loss: 0.0039 - accuracy: 0.9953 - val_loss: 7.5102 - val_accuracy: 0.3925\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 14s 987ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 7.3716 - val_accuracy: 0.4019\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0035 - accuracy: 0.9977 - val_loss: 7.5862 - val_accuracy: 0.3925\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0031 - accuracy: 0.9977 - val_loss: 7.5386 - val_accuracy: 0.3925\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 16s 1s/step - loss: 0.0033 - accuracy: 0.9977 - val_loss: 7.5318 - val_accuracy: 0.4112\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 14s 1s/step - loss: 0.0036 - accuracy: 0.9953 - val_loss: 7.5355 - val_accuracy: 0.3925\n",
            "4/4 [==============================] - 1s 314ms/step - loss: 7.5355 - accuracy: 0.3925\n",
            "Accuracy: 0.3925233781337738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the model predictions on the test set\n",
        "y_pred_prob = model.predict(X_test_padded)\n",
        "y_pred_labels = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Invert one-hot encoding for y_test\n",
        "y_test_labels = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test_labels, y_pred_labels, average='macro')\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate ROC-AUC curve\n",
        "roc_auc = roc_auc_score(y_test_onehot, y_pred_prob, average='macro')\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "# Plot ROC curve for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc_per_class = dict()\n",
        "\n"
      ],
      "metadata": {
        "id": "gpa3X_5OdW47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb4eda7-b782-4fa4-994d-1eaf9d0e4bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 407ms/step\n",
            "F1 Score: 0.4013986013986014\n",
            "Confusion Matrix:\n",
            "[[23 38]\n",
            " [26 20]]\n",
            "ROC-AUC Score: 0.36003207412687094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the user input\n",
        "user_text = input(\"Enter text: \")\n",
        "user_text_seq = tokenizer.texts_to_sequences([user_text])\n",
        "user_text_padded = pad_sequences(user_text_seq, maxlen=max_sequence_length)\n",
        "user_prediction = model.predict(user_text_padded)\n",
        "user_prediction_label = np.argmax(user_prediction)  # Get the class index with the highest probability\n",
        "user_prediction_class = label_encoder.inverse_transform([user_prediction_label])[0]\n",
        "\n",
        "print(\"Predicted :\", user_prediction_class)"
      ],
      "metadata": {
        "id": "b343iE-ndhIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f0e92c-519c-49f0-8392-3a01028952a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: A multimedia dictionary using 3D Kanji has been  proposed. This dictionary uses a combination of 3D  Kanji  and  multimedia  name  to  provide  a  multiple  view  of  objects  and  phenomena.  The  3D  Kanji  represents  meaning  through  its  font,  weight,  and  structured  design.  The  multimedia  name  describes  meaning  through  a  set  of  structured  pictures.  An  example of applying the approach as a dictionary for Functions of two holes \n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "Predicted : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow tensorflow-datasets transformers"
      ],
      "metadata": {
        "id": "fwOsbh6reIAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = data['content']\n",
        "y = data['class']\n",
        "\n",
        "# Use LabelEncoder to convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Tokenize the text and convert them into input features\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in X:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert lists to tensors\n",
        "input_ids = tf.concat(input_ids, axis=0)\n",
        "attention_masks = tf.concat(attention_masks, axis=0)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_np = np.array(input_ids)\n",
        "y_np = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TensorFlow Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "# Batch the data and shuffle\n",
        "batch_size = 32\n",
        "train_dataset = train_dataset.shuffle(len(X_train)).batch(batch_size)\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "# Load pre-trained BERT model for sequence classification\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
        "\n",
        "# Set up optimizer and loss function\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with hyperparameter tuning\n",
        "epochs = 6\n",
        "history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)\n",
        "\n",
        "# Evaluation on test data\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBiol-ATeL_y",
        "outputId": "b0c4d9f1-4be5-4d04-b000-3d0f09b3b7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "14/14 [==============================] - 796s 54s/step - loss: 1.3020 - accuracy: 0.4122 - val_loss: 0.9782 - val_accuracy: 0.4112\n",
            "Epoch 2/6\n",
            "14/14 [==============================] - 691s 49s/step - loss: 0.8925 - accuracy: 0.5269 - val_loss: 0.8229 - val_accuracy: 0.4206\n",
            "Epoch 3/6\n",
            "14/14 [==============================] - 726s 52s/step - loss: 0.7867 - accuracy: 0.5504 - val_loss: 0.7999 - val_accuracy: 0.4206\n",
            "Epoch 4/6\n",
            "14/14 [==============================] - 717s 51s/step - loss: 0.7173 - accuracy: 0.6066 - val_loss: 0.7784 - val_accuracy: 0.4206\n",
            "Epoch 5/6\n",
            "14/14 [==============================] - 715s 51s/step - loss: 0.6721 - accuracy: 0.6604 - val_loss: 0.7369 - val_accuracy: 0.5514\n",
            "Epoch 6/6\n",
            "14/14 [==============================] - 686s 49s/step - loss: 0.5800 - accuracy: 0.7611 - val_loss: 0.7592 - val_accuracy: 0.5047\n",
            "4/4 [==============================] - 48s 11s/step - loss: 0.7592 - accuracy: 0.5047\n",
            "Test Accuracy: 50.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KLTJDxJGd6r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)  # Change num_labels based on your problem\n",
        "\n",
        "class_names = ['1', '0']  # Replace with actual class names\n"
      ],
      "metadata": {
        "id": "FGQWRbAJd_Ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0f993a-8d3f-450b-a0e1-b574fe9137e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text):\n",
        "    # Tokenize and preprocess the input text\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_dict['input_ids']\n",
        "    attention_mask = encoded_dict['attention_mask']\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    logits = model([input_ids, attention_mask])[0]\n",
        "    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n",
        "    prediction = class_names[predicted_class]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Get user input and make predictions\n",
        "user_input = input(\"Enter text: \")\n",
        "prediction = predict_text(user_input)\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "hr2JH4Wve526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071876d6-45f3-4d8d-90d5-8683ca099585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: A multimedia dictionary using 3D Kanji has been  proposed. This dictionary uses a combination of 3D  Kanji  and  multimedia  name  to  provide  a  multiple  view  of  objects  and  phenomena.  The  3D  Kanji  represents  meaning  through  its  font,  weight,  and  structured  design.  The  multimedia  name  describes  meaning  through  a  set  of  structured  pictures.  An  example of applying the approach as a dictionary for Functions of two holes \n",
            "Prediction: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "h5yP47zwe7cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = data['content']\n",
        "y = data['class']\n",
        "\n",
        "# Use LabelEncoder to convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "\n",
        "# Define vocabulary size and embedding dimensions\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 100  # You can adjust this dimension based on your preference and dataset characteristics\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(128,))  # Assuming the maximum sequence length is 128\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
        "\n",
        "# Convolutional layers\n",
        "conv_layer = Conv1D(filters=128, kernel_size=5, activation='relu')(embedding_layer)\n",
        "global_max_pooling = GlobalMaxPooling1D()(conv_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer = Dense(512, activation='relu')(global_max_pooling)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
        "\n",
        "# Create the model\n",
        "cnn_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MfDQa09Re-Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_train to NumPy array if it's not already\n",
        "X_train = np.array(input_ids)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.9, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "cnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluation on test data\n",
        "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79kAJ3gTfZW_",
        "outputId": "28dadb23-1426-4271-9d40-f59d4742503d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 172ms/step - loss: 0.2489 - accuracy: 0.6667 - val_loss: 0.1705 - val_accuracy: 0.7778\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 0.0604 - accuracy: 0.9286 - val_loss: 0.1559 - val_accuracy: 0.7963\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 0.0201 - accuracy: 0.9762 - val_loss: 0.1414 - val_accuracy: 0.8148\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 166ms/step - loss: 2.8708e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.8148\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 1.6700e-05 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.8148\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 4.3473e-06 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.8148\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 3.0334e-06 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.8333\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 2.4569e-06 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 2.3861e-06 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 2.8289e-06 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.8333\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 2.7775e-06 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8333\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 2.6915e-06 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 2.4346e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 2.2204e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 1.7664e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.5750e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 1.2320e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 1.1157e-06 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 9.4314e-07 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 8.1648e-07 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 165ms/step - loss: 7.3129e-07 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.8333\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.6018e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 6.0820e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 5.5599e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 5.3299e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 5.0466e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 4.7261e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 4.5283e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 173ms/step - loss: 4.3973e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 4.1807e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 4.0754e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 3.9480e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8333\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.8313e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.7246e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 3.6233e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 3.5359e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 3.4553e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 207ms/step - loss: 3.4040e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 3.3313e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 3.2399e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 171ms/step - loss: 3.2033e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.1350e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 3.0883e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 3.0214e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.9925e-07 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.8148\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 2.9372e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 2.9046e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 2.8617e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 168ms/step - loss: 2.8284e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 2.7884e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 170ms/step - loss: 2.7636e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 2.7318e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 2.7002e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 2.6774e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 2.6510e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 2.6228e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 2.5997e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 2.5790e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 2.5517e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 2.5284e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 2.5106e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 2.4833e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 2.4593e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 2.4446e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 2.4203e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 2.4000e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 2.3772e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 2.3581e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 2.3380e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 2.3178e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 2.3030e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 2.2789e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 2.2655e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 2.2428e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 2.2265e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 2.2123e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 2.1904e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 2.1787e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 2.1584e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 2.1430e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 2.1284e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 2.1106e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 2.0963e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 2.0826e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 2.0682e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 2.0549e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 2.0406e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 2.0293e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 2.0176e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 2.0033e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 1.9915e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 1.9801e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.9666e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.9546e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 1.9441e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 1.9302e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 1.9166e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.9086e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 1.8961e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 1.8808e-07 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.8148\n",
            "16/16 [==============================] - 0s 18ms/step - loss: 0.1636 - accuracy: 0.7921\n",
            "Test Accuracy: 79.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_cnn(text):\n",
        "    encoded_text = tokenizer.encode(text, add_special_tokens=True)\n",
        "    padded_text = tf.keras.preprocessing.sequence.pad_sequences([encoded_text], maxlen=128, padding='post')\n",
        "\n",
        "    prediction = cnn_model.predict(padded_text)\n",
        "    predicted_class = 1 if prediction > 0.5 else 0\n",
        "    prediction_label = class_names[predicted_class]\n",
        "\n",
        "    return prediction_label\n"
      ],
      "metadata": {
        "id": "2i3WH7hpfg6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input and make predictions\n",
        "user_input = input(\"Enter text: \")\n",
        "prediction = predict_text_cnn(user_input)\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ANcbRyUoflsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "7XF7w1zNf7s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = data['content']\n",
        "y = data['class']\n",
        "\n",
        "# Use LabelEncoder to convert labels to integers\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Tokenize the text and convert them into input features\n",
        "# ...\n",
        "\n",
        "# Define vocabulary size and embedding dimensions\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 100  # You can adjust this dimension based on your preference and dataset characteristics\n",
        "\n",
        "# Input layer\n",
        "input_layer = Input(shape=(128,))  # Assuming the maximum sequence length is 128\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
        "\n",
        "# GRU layer\n",
        "gru_layer = GRU(128)(embedding_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer = Dense(64, activation='relu')(gru_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer)"
      ],
      "metadata": {
        "id": "XZ_uG8iXgJyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "gru_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Convert X_train to NumPy array if it's not already\n",
        "X_train = np.array(input_ids)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.9, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gru_model.fit(X_train, y_train, epochs=70, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluation on test data\n",
        "loss, accuracy = gru_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfZoY7CNgpK6",
        "outputId": "c06293a4-3eb2-4984-ca26-788c9ce0caa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "2/2 [==============================] - 2s 447ms/step - loss: 4.3325e-05 - accuracy: 1.0000 - val_loss: 3.6955 - val_accuracy: 0.1818\n",
            "Epoch 2/70\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 2.4336e-06 - accuracy: 1.0000 - val_loss: 4.3523 - val_accuracy: 0.1818\n",
            "Epoch 3/70\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 4.2977e-06 - accuracy: 1.0000 - val_loss: 4.8207 - val_accuracy: 0.2727\n",
            "Epoch 4/70\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 6.2092e-06 - accuracy: 1.0000 - val_loss: 5.0981 - val_accuracy: 0.2727\n",
            "Epoch 5/70\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 4.2851e-06 - accuracy: 1.0000 - val_loss: 5.2150 - val_accuracy: 0.2727\n",
            "Epoch 6/70\n",
            "2/2 [==============================] - 0s 107ms/step - loss: 2.6386e-06 - accuracy: 1.0000 - val_loss: 5.2384 - val_accuracy: 0.2727\n",
            "Epoch 7/70\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 1.2951e-06 - accuracy: 1.0000 - val_loss: 5.2320 - val_accuracy: 0.2727\n",
            "Epoch 8/70\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 7.6590e-07 - accuracy: 1.0000 - val_loss: 5.2080 - val_accuracy: 0.2727\n",
            "Epoch 9/70\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 4.5535e-07 - accuracy: 1.0000 - val_loss: 5.1805 - val_accuracy: 0.2727\n",
            "Epoch 10/70\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 3.0431e-07 - accuracy: 1.0000 - val_loss: 5.1524 - val_accuracy: 0.1818\n",
            "Epoch 11/70\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 2.1281e-07 - accuracy: 1.0000 - val_loss: 5.1256 - val_accuracy: 0.1818\n",
            "Epoch 12/70\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 1.5947e-07 - accuracy: 1.0000 - val_loss: 5.1014 - val_accuracy: 0.1818\n",
            "Epoch 13/70\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 1.2332e-07 - accuracy: 1.0000 - val_loss: 5.0798 - val_accuracy: 0.1818\n",
            "Epoch 14/70\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 1.0087e-07 - accuracy: 1.0000 - val_loss: 5.0607 - val_accuracy: 0.1818\n",
            "Epoch 15/70\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 8.4078e-08 - accuracy: 1.0000 - val_loss: 5.0436 - val_accuracy: 0.0909\n",
            "Epoch 16/70\n",
            "2/2 [==============================] - 0s 179ms/step - loss: 7.4330e-08 - accuracy: 1.0000 - val_loss: 5.0282 - val_accuracy: 0.0909\n",
            "Epoch 17/70\n",
            "2/2 [==============================] - 0s 205ms/step - loss: 6.5930e-08 - accuracy: 1.0000 - val_loss: 5.0147 - val_accuracy: 0.1818\n",
            "Epoch 18/70\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 5.9966e-08 - accuracy: 1.0000 - val_loss: 5.0028 - val_accuracy: 0.1818\n",
            "Epoch 19/70\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 5.4934e-08 - accuracy: 1.0000 - val_loss: 4.9923 - val_accuracy: 0.1818\n",
            "Epoch 20/70\n",
            "2/2 [==============================] - 0s 177ms/step - loss: 5.1896e-08 - accuracy: 1.0000 - val_loss: 4.9830 - val_accuracy: 0.1818\n",
            "Epoch 21/70\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 4.8322e-08 - accuracy: 1.0000 - val_loss: 4.9749 - val_accuracy: 0.1818\n",
            "Epoch 22/70\n",
            "2/2 [==============================] - 0s 185ms/step - loss: 4.6219e-08 - accuracy: 1.0000 - val_loss: 4.9676 - val_accuracy: 0.1818\n",
            "Epoch 23/70\n",
            "2/2 [==============================] - 0s 181ms/step - loss: 4.4211e-08 - accuracy: 1.0000 - val_loss: 4.9610 - val_accuracy: 0.1818\n",
            "Epoch 24/70\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 4.2573e-08 - accuracy: 1.0000 - val_loss: 4.9550 - val_accuracy: 0.1818\n",
            "Epoch 25/70\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 4.1210e-08 - accuracy: 1.0000 - val_loss: 4.9495 - val_accuracy: 0.1818\n",
            "Epoch 26/70\n",
            "2/2 [==============================] - 0s 195ms/step - loss: 4.0109e-08 - accuracy: 1.0000 - val_loss: 4.9445 - val_accuracy: 0.1818\n",
            "Epoch 27/70\n",
            "2/2 [==============================] - 0s 184ms/step - loss: 3.9186e-08 - accuracy: 1.0000 - val_loss: 4.9400 - val_accuracy: 0.1818\n",
            "Epoch 28/70\n",
            "2/2 [==============================] - 0s 207ms/step - loss: 3.8185e-08 - accuracy: 1.0000 - val_loss: 4.9364 - val_accuracy: 0.1818\n",
            "Epoch 29/70\n",
            "2/2 [==============================] - 0s 182ms/step - loss: 3.7356e-08 - accuracy: 1.0000 - val_loss: 4.9331 - val_accuracy: 0.1818\n",
            "Epoch 30/70\n",
            "2/2 [==============================] - 0s 190ms/step - loss: 3.6787e-08 - accuracy: 1.0000 - val_loss: 4.9301 - val_accuracy: 0.1818\n",
            "Epoch 31/70\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 3.6117e-08 - accuracy: 1.0000 - val_loss: 4.9275 - val_accuracy: 0.1818\n",
            "Epoch 32/70\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 3.5511e-08 - accuracy: 1.0000 - val_loss: 4.9252 - val_accuracy: 0.1818\n",
            "Epoch 33/70\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 3.4988e-08 - accuracy: 1.0000 - val_loss: 4.9229 - val_accuracy: 0.1818\n",
            "Epoch 34/70\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 3.4573e-08 - accuracy: 1.0000 - val_loss: 4.9209 - val_accuracy: 0.1818\n",
            "Epoch 35/70\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 3.4073e-08 - accuracy: 1.0000 - val_loss: 4.9190 - val_accuracy: 0.1818\n",
            "Epoch 36/70\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 3.3668e-08 - accuracy: 1.0000 - val_loss: 4.9171 - val_accuracy: 0.1818\n",
            "Epoch 37/70\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 3.3282e-08 - accuracy: 1.0000 - val_loss: 4.9152 - val_accuracy: 0.1818\n",
            "Epoch 38/70\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 3.2930e-08 - accuracy: 1.0000 - val_loss: 4.9133 - val_accuracy: 0.1818\n",
            "Epoch 39/70\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 3.2551e-08 - accuracy: 1.0000 - val_loss: 4.9115 - val_accuracy: 0.1818\n",
            "Epoch 40/70\n",
            "2/2 [==============================] - 0s 121ms/step - loss: 3.2252e-08 - accuracy: 1.0000 - val_loss: 4.9097 - val_accuracy: 0.1818\n",
            "Epoch 41/70\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 3.1936e-08 - accuracy: 1.0000 - val_loss: 4.9079 - val_accuracy: 0.1818\n",
            "Epoch 42/70\n",
            "2/2 [==============================] - 0s 210ms/step - loss: 3.1648e-08 - accuracy: 1.0000 - val_loss: 4.9061 - val_accuracy: 0.1818\n",
            "Epoch 43/70\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 3.1329e-08 - accuracy: 1.0000 - val_loss: 4.9044 - val_accuracy: 0.1818\n",
            "Epoch 44/70\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 3.1069e-08 - accuracy: 1.0000 - val_loss: 4.9027 - val_accuracy: 0.1818\n",
            "Epoch 45/70\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 3.0776e-08 - accuracy: 1.0000 - val_loss: 4.9013 - val_accuracy: 0.1818\n",
            "Epoch 46/70\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 3.0523e-08 - accuracy: 1.0000 - val_loss: 4.9000 - val_accuracy: 0.1818\n",
            "Epoch 47/70\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 3.0215e-08 - accuracy: 1.0000 - val_loss: 4.8987 - val_accuracy: 0.1818\n",
            "Epoch 48/70\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 2.9946e-08 - accuracy: 1.0000 - val_loss: 4.8976 - val_accuracy: 0.1818\n",
            "Epoch 49/70\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 2.9707e-08 - accuracy: 1.0000 - val_loss: 4.8967 - val_accuracy: 0.1818\n",
            "Epoch 50/70\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 2.9450e-08 - accuracy: 1.0000 - val_loss: 4.8957 - val_accuracy: 0.1818\n",
            "Epoch 51/70\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 2.9208e-08 - accuracy: 1.0000 - val_loss: 4.8948 - val_accuracy: 0.1818\n",
            "Epoch 52/70\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.8954e-08 - accuracy: 1.0000 - val_loss: 4.8940 - val_accuracy: 0.1818\n",
            "Epoch 53/70\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 2.8740e-08 - accuracy: 1.0000 - val_loss: 4.8931 - val_accuracy: 0.1818\n",
            "Epoch 54/70\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 2.8517e-08 - accuracy: 1.0000 - val_loss: 4.8921 - val_accuracy: 0.1818\n",
            "Epoch 55/70\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.8296e-08 - accuracy: 1.0000 - val_loss: 4.8911 - val_accuracy: 0.1818\n",
            "Epoch 56/70\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.8091e-08 - accuracy: 1.0000 - val_loss: 4.8900 - val_accuracy: 0.1818\n",
            "Epoch 57/70\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 2.7879e-08 - accuracy: 1.0000 - val_loss: 4.8889 - val_accuracy: 0.1818\n",
            "Epoch 58/70\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 2.7656e-08 - accuracy: 1.0000 - val_loss: 4.8878 - val_accuracy: 0.1818\n",
            "Epoch 59/70\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 2.7476e-08 - accuracy: 1.0000 - val_loss: 4.8868 - val_accuracy: 0.1818\n",
            "Epoch 60/70\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 2.7241e-08 - accuracy: 1.0000 - val_loss: 4.8858 - val_accuracy: 0.1818\n",
            "Epoch 61/70\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 2.7076e-08 - accuracy: 1.0000 - val_loss: 4.8847 - val_accuracy: 0.1818\n",
            "Epoch 62/70\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 2.6854e-08 - accuracy: 1.0000 - val_loss: 4.8837 - val_accuracy: 0.1818\n",
            "Epoch 63/70\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 2.6674e-08 - accuracy: 1.0000 - val_loss: 4.8827 - val_accuracy: 0.1818\n",
            "Epoch 64/70\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.6475e-08 - accuracy: 1.0000 - val_loss: 4.8819 - val_accuracy: 0.1818\n",
            "Epoch 65/70\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 2.6291e-08 - accuracy: 1.0000 - val_loss: 4.8812 - val_accuracy: 0.1818\n",
            "Epoch 66/70\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 2.6119e-08 - accuracy: 1.0000 - val_loss: 4.8806 - val_accuracy: 0.1818\n",
            "Epoch 67/70\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 2.5917e-08 - accuracy: 1.0000 - val_loss: 4.8800 - val_accuracy: 0.1818\n",
            "Epoch 68/70\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.5765e-08 - accuracy: 1.0000 - val_loss: 4.8793 - val_accuracy: 0.1818\n",
            "Epoch 69/70\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.5576e-08 - accuracy: 1.0000 - val_loss: 4.8787 - val_accuracy: 0.1818\n",
            "Epoch 70/70\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 2.5412e-08 - accuracy: 1.0000 - val_loss: 4.8780 - val_accuracy: 0.1818\n",
            "16/16 [==============================] - 0s 19ms/step - loss: 0.7470 - accuracy: 0.8649\n",
            "Test Accuracy: 86.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer  # You might need to import this depending on your tokenization\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "di1z6l6Pg2B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Load your GRU model here\n",
        "# gru_model = ...\n",
        "\n",
        "class_names = ['1', '0']  # Replace with actual class names"
      ],
      "metadata": {
        "id": "YAmFWyW8g8F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text_gru(text):\n",
        "    # Tokenize and preprocess the input text\n",
        "    encoded_text = tokenizer.encode(text, add_special_tokens=True)\n",
        "    padded_text = tf.keras.preprocessing.sequence.pad_sequences([encoded_text], maxlen=128, padding='post')\n",
        "\n",
        "    # Make a prediction using the GRU model\n",
        "    prediction = gru_model.predict(padded_text)\n",
        "    predicted_class = 1 if prediction > 0.5 else 0\n",
        "    prediction_label = class_names[predicted_class]\n",
        "\n",
        "    return prediction_label\n",
        "\n",
        "# Get user input and make predictions\n",
        "user_input = input(\"Enter text: \")\n",
        "prediction = predict_text_gru(user_input)\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOY0hWHFhCbk",
        "outputId": "9715ec48-6bca-47a5-b303-787bf08e5341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: A multimedia dictionary using 3D Kanji has been  proposed. This dictionary uses a combination of 3D  Kanji  and  multimedia  name  to  provide  a  multiple  view  of  objects  and  phenomena.  The  3D  Kanji  represents  meaning  through  its  font,  weight,  and  structured  design.  The  multimedia  name  describes  meaning  through  a  set  of  structured  pictures.  An  example of applying the approach as a dictionary for Functions of two holes \n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Prediction: 0\n"
          ]
        }
      ]
    }
  ]
}